{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nIBcFFBZ2pK"
   },
   "source": [
    "# Signal Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46R047xRZ2pN"
   },
   "source": [
    "Author: Ziad - Doaa - Osama (521237)\n",
    "\n",
    "Review of different models and techniques used for signal classification. The models are implemented in Python and some in MATLAB. \n",
    "The methods and models that I have built for the comparison are listed below.\n",
    "The complete code for the implementation of all the model can be found on their respective files, which are indicated on the description of each section.\n",
    "<br/>\n",
    "### Models:\n",
    " * **Feature extraction + Classifier**\n",
    "\n",
    " * **Automated feature extraction + Classifier**\n",
    "\n",
    " * **CNN_1D** (1-dimensional convolutional network)\n",
    "\n",
    " * **LSTM** (Long short-term memory neural network)\n",
    "\n",
    " * **CNN_1D + LSTM**\n",
    "\n",
    " * **CWT + CNN_2D** (Continuous wavelet transform + 2D convolutional network)\n",
    " \n",
    " * **Wavelet Time Scattering + Classifier**\n",
    "\n",
    "<br/>\n",
    "\n",
    "I will be using the data set \"Human Activity Recognition Using Smartphones\" from the UCI database. \n",
    "The experiment consists of a set of people performing six activities (WALKING, WALKING UPSTAIRS, WALKING DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. \n",
    "The embedded accelerometer and gyroscope of the phone is then used to record the 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The objective is to predict which activity is performing the person.\n",
    "\n",
    "Each sample individual sample we have 9 signals with a total length of 128 readings:\n",
    "\n",
    "body_acc_x_train, body_acc_y_train, body_acc_z_train, body_gyro_x_train, body_gyro_y_train, body_gyro_z_train, total_acc_x_train, total_acc_y_train, total_acc_z_train\n",
    "\n",
    "Activities description:\n",
    "1. walking\n",
    "2. walking upstairs\n",
    "3. walking downstairs\n",
    "4. sitting\n",
    "5. standing\n",
    "6. laying\n",
    " \n",
    "\n",
    " \n",
    "The original data set: <br>\n",
    "https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**References & resources**\n",
    "\n",
    "Here some materials and resources from which I have learned some of the methods shown on this notebook and that I would recommend to people starting learning about signal processing and classification.\n",
    "\n",
    "\n",
    "* \"*Signal processing problems, solved in MATLAB and in Python\", by Mike X Cohen (Udemy Course).* <a href=\"https://www.udemy.com/course/signal-processing/\"> Link</a>. \n",
    "\n",
    "* *Signal Processing Toolbox documentation (tutorials and examples).* <a href=\"https://www.mathworks.com/help/signal/signal-generation-and-preprocessing.html?category=signal-generation-and-preprocessing&s_tid=CRUX_gn_documentation_signal-generation-and-preprocessing\"> Link</a>.\n",
    "\n",
    "* \"*Deep Learning for Time Series Forecasting\", by Jason Brownlee* (Book).\n",
    "\n",
    "* *Ahmet Taspinar blog (Deep learning blog).* <a href=\"http://ataspinar.com/\"> Link</a>.\n",
    "\n",
    "* *UTU Deep Learning Course (TKO_ 8612).* <a href=\"https://opas.peppi.utu.fi/en/course/TKO_8612/8225\"> Link</a>.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYhvj7YaQsZR"
   },
   "source": [
    "**Free cloud GPU servers**\n",
    "\n",
    "- Google colab (TPU / GPU  Nvidia T4s, K80s, P4s and P100s)\n",
    "- Kaggle kernel (GPU Nvidia Telsa P100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "colab_type": "code",
    "id": "euc-V3LQa9v0",
    "outputId": "19455870-b84d-4c3f-fe4f-378693edd101"
   },
   "outputs": [],
   "source": [
    "# # Just uploading this notebook and running this cell it should be ready to go.\n",
    "\n",
    "# !apt install git\n",
    "# !git clone https://github.com/JoaquinRives/Deep-Learning-Project\n",
    "# !pip install -r Deep-Learning-Project/requirements.txt\n",
    "\n",
    "# import os\n",
    "# os.chdir(\"Signal_Classification_Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7k9ER4jvZ2pO"
   },
   "source": [
    "<br>\n",
    "\n",
    "## Signals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFOubPD_Z2pO"
   },
   "outputs": [],
   "source": [
    "from data_handling import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "WBz3y6M2Z2pS",
    "outputId": "1b46950d-9991-495e-f56b-4c7dadccde6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 7352 signals, each one of length 128 and 9 components \n",
      "The test dataset contains 2947 signals, each one of length 128 and 9 components \n",
      "The train dataset contains 7352 labels, with the following distribution:\n",
      " Counter({6: 1407, 5: 1374, 4: 1286, 1: 1226, 2: 1073, 3: 986})\n",
      "The test dataset contains 2947 labels, with the following distribution:\n",
      " Counter({6: 537, 5: 532, 1: 496, 4: 491, 2: 471, 3: 420})\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I10xIJkfZ2pV"
   },
   "source": [
    "#### Plot the distribution of each signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "lSxdn4PrZ2pW",
    "outputId": "3aa3741f-9efd-40f1-eb35-d4fc6d28a5ed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAEvCAYAAADMyFxmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 9 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_variable_distributions(trainX):\n",
    "    \"\"\" Plots a histogram of each variable in the data set \"\"\"\n",
    "    # remove overlap\n",
    "    cut = int(trainX.shape[1] / 2)\n",
    "    longX = trainX[:, -cut:, :]\n",
    "    # flatten windows\n",
    "    longX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n",
    "    plt.figure()\n",
    "    xaxis = None\n",
    "    for i in range(longX.shape[1]):\n",
    "        ax = plt.subplot(longX.shape[1], 1, i+1, sharex=xaxis)\n",
    "        ax.set_xlim(-1, 1)\n",
    "        if i == 0:\n",
    "            xaxis = ax\n",
    "        plt.hist(longX[:, i], bins=100)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Plot a histogram of each signal\n",
    "plot_variable_distributions(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3wEXbydZ2pZ"
   },
   "source": [
    "#### Plot the distribution of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "4UR0m43VZ2pa",
    "outputId": "69d12f0e-42d5-4cee-955e-2e96a5c7a213"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAE/CAYAAAD2ee+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6pRBTZIkqVP/H5YFhMB6Bp6jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count plot of the target labels\n",
    "sns.countplot(y_train, )\n",
    "plt.title(\"Label distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFtRmuSeZ2pc"
   },
   "source": [
    "\n",
    "<br/>\n",
    "\n",
    "## Feature extraction + Classifier\n",
    "<br/>\n",
    "\n",
    "Code implementation:\n",
    "> **feature_extraction.py**\n",
    "\n",
    "\n",
    "One of the most commonly used methods for signal classification consist on, instead of passing directly the signal to the model, extract features from the signal and pass those signals to a classifier model. The signals that I have extracted are:\n",
    "\n",
    "* **FFT :**  The coordinates in axis x and y of the n first significant peaks of the signal in the frequency domain after applying the Fast Fourier Transform.\n",
    "* **PSD :**  First n significant peaks from the Power Spectral Density analysis of the signal.\n",
    "* **Autocorrelation :**  First n significant peaks of the auto-correlation coefficients.\n",
    "* **Entropy (Shannon)**\n",
    "* **Zero crossing rate**\n",
    "* **Mean crossing rate**\n",
    "* **Statistic features :**  (n5, n25, n75, n95, median, mean, std, var, rms)\n",
    "\n",
    "Many more features can be extracted, the ones shown here are just a representation of the most commonly used. Domain-knowledge of the signals we want to classify is important in order to know which features we should extract for a better classification.\n",
    "All the features are passed as a sigle vector to the classifier. The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-YFEVRZZ2pd",
    "outputId": "d7f57c3f-7c12-46c4-9abc-56508ee61948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Average score: 91.483% (+/-0.000)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=300,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------\n",
      "Average score: 93.858% (+/-0.000)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=30, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=300,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------\n",
      "Average score: 91.110% (+/-0.000)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('svc',\n",
      "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
      "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
      "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
      "                     probability=False, random_state=None, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------\n",
      "Average score: 87.173% (+/-0.000)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=5, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------\n",
      "Average score: 90.797% (+/-0.152)\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) \n",
      "\n",
      "----------------------------------------\n",
      "Average score: 88.660% (+/-0.578)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False) \n",
      "\n",
      "----------------------------------------\n",
      "Average score: 93.760% (+/-0.065)\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import feature_extraction\n",
    "\n",
    "# Run experiment:each experiments is repeated n times and the average\n",
    "# and standard deviation of the results is calculated\n",
    "feature_extraction.run_experiment(repeats=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bLzws9-Z2pg"
   },
   "source": [
    "<br/>\n",
    "\n",
    "## Automated Feature Extraction + Classifier\n",
    "\n",
    "Code implementation:\n",
    "> automated_feature_extraction/extract_features.py<br/>\n",
    "> automated_feature_extraction/select_features.py<br/>\n",
    "> automated_feature_extraction/train_and_evaluate.py<br/>\n",
    "\n",
    "Another way of extracting features is using a package like tfresh (https://tsfresh.readthedocs.io/), which can be used to extract automatically a very large number of features (over 700 hundred features). Besides extracting the features, it can also be used for feature selection.\n",
    "The drawback is the computational time that it takes to extract all the features. It over 2 hours on my laptop (i7, 16Gb RAM).\n",
    "> $ pip install tfresh\n",
    "\n",
    "As the signals have 9 components, I have done the extraction and selection independently for each component and then concatenated all the features together before fitting the model.\n",
    "\n",
    "The total number of features extracted from each signal was is 6786, from which 1793 were selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wIyQ54nvTzvR"
   },
   "outputs": [],
   "source": [
    "from auto_feature_extraction import extract_features, select_features, train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2YFGXjqZ2ph",
    "outputId": "83cf1dcf-b89b-418b-a848-3c2688a997f8"
   },
   "outputs": [],
   "source": [
    "extract_features.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrZ5ua_JZ2pj",
    "outputId": "fb6e8917-30a9-4b6c-9439-dee0d4a2fe2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading signal_comp_0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 203 features.\n",
      "loading signal_comp_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 166 features.\n",
      "loading signal_comp_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 184 features.\n",
      "loading signal_comp_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 154 features.\n",
      "loading signal_comp_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 178 features.\n",
      "loading signal_comp_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 177 features.\n",
      "loading signal_comp_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 261 features.\n",
      "loading signal_comp_7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 234 features.\n",
      "loading signal_comp_8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting features...\n",
      "selected 236 features.\n",
      "saving automatic_feature_extraction/data_selected/train.csv\n",
      "saving automatic_feature_extraction/data_selected/test.csv\n"
     ]
    }
   ],
   "source": [
    "select_features.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwaspI9uZ2pm",
    "outputId": "3709f2b7-a0cc-49ba-90e5-b077c615c626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.34% \n",
      "\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=300,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "\n",
      "\n",
      "Accuracy: 87.45% \n",
      "\n",
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=30, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=300,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "\n",
      "\n",
      "Accuracy: 73.51% \n",
      "\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('svc',\n",
      "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
      "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
      "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
      "                     probability=False, random_state=None, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "\n",
      "\n",
      "Accuracy: 81.50% \n",
      "\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=5, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "\n",
      "\n",
      "Accuracy: 89.09% \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Accuracy: 83.26% \n",
      "\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "\n",
      "\n",
      "Accuracy: 86.47% \n",
      "\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(activation='relu', alpha=0.0001,\n",
      "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "                               early_stopping=False, epsilon=1e-08,\n",
      "                               hidden_layer_sizes=(250, 150),\n",
      "                               learning_rate='constant',\n",
      "                               learning_rate_init=0.001, max_fun=15000,\n",
      "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
      "                               nesterovs_momentum=True, power_t=0.5,\n",
      "                               random_state=None, shuffle=True, solver='adam',\n",
      "                               tol=0.0001, validation_fraction=0.1,\n",
      "                               verbose=False, warm_start=False))],\n",
      "         verbose=False)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate.train_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2S_ZPUwwZ2po"
   },
   "source": [
    "The accuracies are a bit lower than in the previous example where the features where specifically selected and extracted. Definitely it isn't worth the amount of time that it took to extract them. Maybe with other data sets the result would be different, but what is clear is that knowing the signal you are working with and which of its features are relevant, is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsWoOFgPZ2pp"
   },
   "source": [
    "<br/>\n",
    "\n",
    "## 1D_Convolutional_Network\n",
    "<br/>\n",
    "\n",
    "Code implementation:\n",
    "\n",
    "> **1D_CNN.py**\n",
    "\n",
    "<br/>\n",
    "The next model is a 1-dimensional multi-headed convolutional network, where each head of the model reads the input time steps using a different sized kernel (3, 5, 11) allowing the model to read and interpret the sequence data at three different resolutions. The interpretations from all three heads are then concatenated within the model and interpreted by a fully connected layer before a prediction is made.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<img src=\"data/img_models/multihead_1D_CNN.png\" />\n",
    "\n",
    "***\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "4M19esjiZ2pq",
    "outputId": "7895d7e8-3cc5-41e0-aef1-32af1f29d7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Rep_1: 92.057\n",
      "> Rep_2: 93.347\n",
      "> Rep_3: 93.483\n",
      "> Rep_4: 92.057\n",
      "> Rep_5: 92.600\n",
      "> Rep_6: 91.989\n",
      "> Rep_7: 90.767\n",
      "> Rep_8: 92.193\n",
      "> Rep_9: 92.057\n",
      "> Rep_10: 93.211\n",
      "[92.05702647657841, 93.346911065852, 93.48268839103869, 92.05702647657841, 92.60013577732519, 91.98913781398507, 90.76714188730483, 92.1928038017651, 92.05702647657841, 93.2111337406653]\n",
      "Score: 92.376% (+/-0.774)\n"
     ]
    }
   ],
   "source": [
    "import CNN_1D\n",
    "\n",
    "CNN_1D.run_experiment(repeats=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D46lIrLh0qzh"
   },
   "source": [
    "The accuracy achieved is **92.674%** with a standard deviation of 0,521. The 1D_CNN does a good job at identifying the activity from the signals, and with a bit of parameter tunning it could probably be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pR60XhLqZ2ps"
   },
   "source": [
    "<br>\n",
    "\n",
    "## LSTM\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Code implementation:\n",
    "> **LSTM.py**\n",
    "\n",
    "\n",
    "\n",
    "Recurrent neural networks are also very popular on time-series data. Recurrent neural network (RNN) have \"memory\", being able of remember input from the past. Long short-term memory (LSTM) networks are one of the most useful types of RNN architecture thanks to their characteristic use of \"gates\" to reduce the error that would be back-propagated through time and layers otherwise.\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "<img src=\"data/img_models/LSTM.png\" />\n",
    "\n",
    "***\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "i3A5CpGPZ2pt",
    "outputId": "31a12081-86c5-4ec1-b254-1c99b939ab1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Rep_1: 97.246\n",
      "> Rep_2: 96.799\n",
      "> Rep_3: 96.991\n",
      "> Rep_4: 96.986\n",
      "> Rep_5: 96.850\n",
      "[97.24578844477534, 96.7990067517268, 96.99129260593566, 96.98563689978438, 96.84990590655039]\n",
      "Score: 96.974% (+/-0.155)\n"
     ]
    }
   ],
   "source": [
    "import LSTM\n",
    "\n",
    "LSTM.run_experiment(repeats=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EP58PR_4z4f8"
   },
   "source": [
    "The results are pretty good, **96.974% (+/-0.155)** accuracy. Even better than the the maximum accuracy achieved by feature extraction, and with the advantage that it isn't needed to expend time extracting features or have any knowledge about the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_UFA2RbZ2px"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## CNN_1D + LSTM\n",
    "\n",
    "<br>\n",
    "\n",
    "Code implemetation:\n",
    "\n",
    "> **CNN_1D_LSTM.py**\n",
    "\n",
    "\n",
    "\n",
    "This conbination can be very powerful. On this model the CNN layers of the model read subsequences of the main sequence as in blocks, extracting features and temporal patterns from each block, then allowing the LSTM to interpret the features extracted from each block. It is very useful when the sequences are to large for the LSTM to remember, as the CNN layers will \"compress\" the sequence.\n",
    "\n",
    "This combination can also give very great results when the features in the signal that we want to detect are spreaded on time, and the exact position of those features isn't relevant.\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "\n",
    "<img src=\"data/img_models/CNN_1D_LSTM.png\" />\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "BxZMgz28Z2py",
    "outputId": "987e714b-217e-4091-9a75-428750f1d269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==>Kernel: (3, 3)\n",
      "> Rep_1: 96.911\n",
      "> Rep_2: 97.613\n",
      "> Rep_3: 96.934\n",
      "> Rep_4: 97.635\n",
      "> Rep_5: 97.251\n",
      "> Rep_6: 97.318\n",
      "> Rep_7: 97.103\n",
      "\n",
      "==>Kernel: (5, 7)\n",
      "> Rep_1: 97.160\n",
      "> Rep_2: 97.307\n",
      "> Rep_3: 97.296\n",
      "> Rep_4: 97.284\n",
      "> Rep_5: 97.364\n",
      "> Rep_6: 97.748\n",
      "> Rep_7: 97.284\n",
      "\n",
      "==>Kernel: (11, 13)\n",
      "> Rep_1: 97.850\n",
      "> Rep_2: 97.149\n",
      "> Rep_3: 96.911\n",
      "> Rep_4: 97.499\n",
      "> Rep_5: 97.183\n",
      "> Rep_6: 96.956\n",
      "> Rep_7: 96.877\n",
      "[[96.91106677055359, 97.61257767677307, 96.93369269371033, 97.63520956039429, 97.25051522254944, 97.31837511062622, 97.1034049987793], [97.16000556945801, 97.30706214904785, 97.29578495025635, 97.28445410728455, 97.36364483833313, 97.74836897850037, 97.28445410728455], [97.85018563270569, 97.14869260787964, 96.91106677055359, 97.49941229820251, 97.18261361122131, 96.95631265640259, 96.87712788581848]] [(3, 3), (5, 7), (11, 13)]\n",
      "Score: 97.268% (+/-0.273)\n",
      "Kernel=(3, 3): 97.252% (+/-0.273)\n",
      "Kernel=(5, 7): 97.349% (+/-0.173)\n",
      "Kernel=(11, 13): 97.204% (+/-0.330)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import CNN_1D_LSTM\n",
    "\n",
    "# Test also using different CNN kernels\n",
    "kernels = [(3, 3), (5, 7) , (11, 13)]\n",
    "\n",
    "# Run experiment\n",
    "CNN_1D_LSTM.run_experiment(repeats=7, kernel=kernels, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJLy2z4-3QUE"
   },
   "source": [
    "Even better, **97.34**% acucuracy. This conbination of 1D_CNN and LSTM give the best results so far. All the kernels give a similar accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_kw6MkOZ2p1"
   },
   "source": [
    "<br>\n",
    "\n",
    "## CWT_2D_CNN\n",
    "\n",
    "\n",
    "Convolution network (2D) on time/frequency representations (scalograms) extracted using the Continuous Wavelet Transform Filter Blank.\n",
    "\n",
    "***\n",
    "\n",
    "> CWT_scalograms.m <br>\n",
    "> data_generator_classes.py <br>\n",
    "> CWT_CNN_MobileNet.py <br>\n",
    "> CWT_CNN_VGG16.py <br>\n",
    "> CWT_3xCNN_VGG16.py <br>\n",
    "\n",
    "***\n",
    "\n",
    "#### Continuous Wavelet Transform Filter Bank\n",
    "\n",
    "On this model the Continuous Wavelet Transform (CWT) is applied to each of the signal and the resulting 2-dimensional coefficient matrix (1 for each signal component) are used as input \"images\" to the model. The resulting input as the following shape: 224,224,9 (height, width, channels), one \"channel\" for each of the signal components (total_acc_x, total_acc_y, total_acc_z,body_acc_x, body_acc_y, body_acc_z, body_gyr_x, body_gyr_y, body_gyr_z).\n",
    "\n",
    "Time/frequency analysis of the signals using the wavelet transform allows us to extract information from the signal in both, frequency and time domains. The wavelet transform filter banks it is also better than other methods as the transformation at different scales achieves the best resolution trade-off between time and frequency (high resolution in the frequency domain for small frequency values | high resolution in the time domain for for large frequency values).\n",
    "\n",
    "I have used MATLAB and the Signal Processing Toolbox to obtain the scalograms.\n",
    "The full code to obtain the scalograms is on the MATLAB file \"**CWT_scalograms.m**\".\n",
    "\n",
    "<br>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"data/data_scalograms/scalogram_example_1.png\" alt=\"Drawing\" width=450/> </td>\n",
    "        <td> <img src=\"data/data_scalograms/scalogram_example_2.png\" alt=\"Drawing\" width=450/> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <img src=\"data/data_scalograms/scalogram_example_3.png\" width=450/> </td>\n",
    "        <td> <img src=\"data/data_scalograms/scalogram_example_4.png\" width=450/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Keras Data Generators\n",
    "\n",
    "To feed the scalograms images to the model we also need to create a custom data_generator. Data_generators are used to load input data from the drive on small batches as needed when training the model. That way we avoid running out of RAM memory when working with large data sets. The generators used here are defined on the \"**data_generator_classes.py**\" file. \n",
    "\n",
    "More info about keras data generators:\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "<br>\n",
    "\n",
    "#### MobileNet\n",
    "\n",
    "#### Input shape \n",
    "\n",
    "For this model I wanted to try using transfer learning from one of the state-of-the-art pre-train models available on keras. To do that we can reuse the convolutional part of the model and remove the top. The pre-trained weights are also kept. Then we add our own dense layers on top so that they can learn to classify our specific data set. (In keras the \"top\" layers means the last layers of the model).\n",
    "\n",
    "However, there is a problem. All the pre-train models (or most of them) have been trained on the \"imagenet\" dataset, which are RGB images (3 channels), if we want to use transfer learning and keep the pre-trained weights of the model, the maximum number of channels that we can pass as input to the model is 3. But we have 9 channels (signal components) that we need to feed to the model. \n",
    "\n",
    "<br>\n",
    "\n",
    "To overcome this problem I have tried 3 possible solutions:\n",
    "\n",
    "\n",
    "**1)**  Not using the pre-trained weigths of the model (no tranfer learning) and use only its architecture. In this case we need to re-train all the layers of the model.\n",
    "\n",
    "\n",
    "**2)**  Concatenate the  scalograms of the 3 axis (x, y, z) of each signal together (kind of a rough solution but I have done it before and it seems to work). That way we reduce from 9 channels to just 3. This is how a single channel would look like:\n",
    "\n",
    "<img src=\"data/data_scalograms/triple_scalogram_example.png\" width=\"350\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "**3)**  Concatenate 3 models on parallel to build a three-headed model, where each head takes a different input (3 signals/channels each head). The outputs of the 3 convolutional heads are then merged together and feeded as input to our dense layers.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtJJOlQDZ2p1"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### 1. CWT_CNN_MobileNet (no transfer learning)\n",
    "\n",
    "<br>\n",
    "\n",
    "Code implementation:\n",
    "\n",
    "> **CWT_CNN_MobileNet.py**\n",
    "\n",
    "<br>\n",
    "\n",
    "MobileNet is a very deep and yet very fast model, as it was originaly designed to be used on mobile and embedded vision applications where the computational power is limited. On this model the weights aren't pre-loaded and all layers are set to be re-trained.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"data/img_models/CWT_CNN_MobileNet_horizontal.png\" />\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before call-back \"ReduceLROnPlateau\" added:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "qxeyPmXLZ2p2",
    "outputId": "8dddcc23-4ec4-4700-fe8f-f85819a1941b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Repeat_1: 64.198\n",
      ">Repeat_2: 54.721\n",
      "[64.1983687877655, 54.721468687057495]\n",
      "Score: 59.460% (+/-4.738)\n"
     ]
    }
   ],
   "source": [
    "import CWT_CNN_MobileNet\n",
    "\n",
    "CWT_CNN_MobileNet.run_experiment(repeats=2, verbose=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "qxeyPmXLZ2p2",
    "outputId": "8dddcc23-4ec4-4700-fe8f-f85819a1941b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      ">Repeat_1: 73.879\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      ">Repeat_2: 67.731\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      ">Repeat_3: 71.365\n",
      "[73.879075050354, 67.73098111152649, 71.365487575531]\n",
      "Score: 70.992% (+/-2.524)\n"
     ]
    }
   ],
   "source": [
    "import CWT_CNN_MobileNet\n",
    "\n",
    "CWT_CNN_MobileNet.run_experiment(repeats=3, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uruNLNjbZ2p4"
   },
   "source": [
    "The results aren't very good, I tried other models (VGG16, ResNet, InceptionV3...), and only MobileNet achieved higher than 70% accuracy. Adding a call-back to reduce the learning rate when the accuracy stagnates seemed to help, the accuracy grew up around 10% after adding it, although more repetitions would be necessary to corroborate that, because the standard deviation is also quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKvn9WoWZ2p7"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2. CWT_CNN_VGG16 (concatenating 3 scalograms on 1 channel)\n",
    "\n",
    "<br>\n",
    "\n",
    "Code implementation:\n",
    "\n",
    "> **CWT_CNN_VGG16.py**\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"data/img_models/CWT_CNN_VGG16_horizontal.png\" />\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "JMkU6jo4Z2p8",
    "outputId": "79a1f1fd-8ddb-4be3-a75a-decce06e4d96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Rep_1: 55.571\n",
      "> Rep_2: 55.027\n",
      "[55.57065010070801, 55.027174949645996]\n",
      "Score: 55.299% (+/-0.272)\n"
     ]
    }
   ],
   "source": [
    "import CWT_CNN_VGG16\n",
    "\n",
    "CWT_CNN_VGG16.run_experiment(repeats=2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofe_kr_RZ2p9"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 3. CWT_3xCNN_VGG16\n",
    "\n",
    "<br>\n",
    "\n",
    "Code implementation:\n",
    "\n",
    "> CWT_3xCNN_VGG16.py\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"data/img_models/CWT_3xCNN_VGG16.png\" />\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "eF_efThU8qcy",
    "outputId": "4d0d7e9d-b19a-4542-d574-cd4b7e8a818b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "> Rep_1: 16.644\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "> Rep_2: 18.037\n",
      "[16.644021739130434, 18.036684782608695]\n",
      "Score: 17.340% (+/-0.696)\n"
     ]
    }
   ],
   "source": [
    "import CWT_3xCNN_VGG16\n",
    "\n",
    "CWT_3xCNN_VGG16.run_experiment(repeats=2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this model are the worst ones, it doesn't seem to learn anything at all. Probably the complexity of the model is excessive. Besides the models shown on this notebook I also tried with more simple models that I built myself, but the results from the scalograms weren't great either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FvyZNgkjZ2qC"
   },
   "source": [
    "<br>\n",
    "\n",
    "## Wavelet Time Scattering + Classifier\n",
    "\n",
    "<br>\n",
    "\n",
    "Code implementation:\n",
    "\n",
    "> **wavelet_scattering.m**\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Wavelet time scattering consist on using wavelets transforms to extract low-variance features from signal, time series or image data. Wavelet time scattering yields signal representations insensitive to shifts in the input signal without sacrificing class discriminability.\n",
    "\n",
    "To extract the scattering features, I have used MATLAB and the Signal Processing Toolbox. The full code is on the MATLAB file \"**wavelet_scattering.m**\".\n",
    "\n",
    "On of the advantages of using wavelet time scattering is its relative high speed and computational efficiency. On my laptop it took less than **4** seconds to extract all of the 1944 features of each signal that are going to be used for the classification.\n",
    "\n",
    "From each signal component, with the wavelet decomposition framework that was used in MATLAB, we obtain 27 features on 8 different time windows *(see on the wavelet_scattering.m script)*. \n",
    "\n",
    "**27** features **&#215; 8** Nwin **&#215; 9** sign_comp  **=**  **1944** total features \n",
    "\n",
    "When can join all the features together or classify each time window independently and then apply majority vote to get the final results. I have put an example using majority vote on the wavelet_scattering.m script. Here for simplicity I am just going to add all the time window features together on a single vector. The accuracy of both methods is almost the same.\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IP2OhdJyZ2qD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Score: 89.82015609093995\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score: 92.29725144214456\n",
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=30, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score: 89.65049202578894\n",
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('svc',\n",
      "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
      "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
      "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
      "                     probability=False, random_state=None, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score: 82.89786223277909\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('kneighborsclassifier',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=5, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score: 90.19341703427214\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Score: 93.28130302002036\n",
      "Pipeline(memory=None,\n",
      "         steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(activation='relu', alpha=0.0001,\n",
      "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
      "                               early_stopping=False, epsilon=1e-08,\n",
      "                               hidden_layer_sizes=(150, 100),\n",
      "                               learning_rate='constant',\n",
      "                               learning_rate_init=0.001, max_fun=15000,\n",
      "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
      "                               nesterovs_momentum=True, power_t=0.5,\n",
      "                               random_state=None, shuffle=True, solver='adam',\n",
      "                               tol=0.0001, validation_fraction=0.1,\n",
      "                               verbose=False, warm_start=False))],\n",
      "         verbose=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def evaluate_model(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    score = acc * 100.0\n",
    "    return score\n",
    "\n",
    "\n",
    "def run_experiment(repeats=2):\n",
    "    # Load data\n",
    "    data_dir = 'data/wavelet_scattering/'\n",
    "    train_features = 'train_WTS_features.mat'\n",
    "    test_file = 'test_WTS_features.mat'\n",
    "\n",
    "    X_train = loadmat(data_dir + 'train_WTS_features.mat')['all_features_train']\n",
    "    X_test = loadmat(data_dir + 'test_WTS_features.mat')['all_features_test']\n",
    "    y_train = loadmat(data_dir + 'train_WTS_labels.mat')['sequence_labels_train'][1, :]\n",
    "    y_test = loadmat(data_dir + 'test_WTS_labels.mat')['sequence_labels_test'][1, :]\n",
    "\n",
    "    time_windows = 8\n",
    "\n",
    "    # Concatenate all the time window features together\n",
    "    train_shape = (X_train.shape[0] // time_windows, X_train.shape[1] * time_windows)\n",
    "    test_shape = (X_test.shape[0] // time_windows, X_test.shape[1] * time_windows)\n",
    "\n",
    "    X_train = np.reshape(X_train, train_shape)\n",
    "    X_test = np.reshape(X_test, test_shape)\n",
    "\n",
    "    # Shuffle data\n",
    "    index = [i for i in range(len(X_train))]\n",
    "    np.random.shuffle(index)\n",
    "    X_train = X_train[index]\n",
    "    y_train = y_train[index]\n",
    "\n",
    "    # Models\n",
    "    classifiers = [\n",
    "        make_pipeline(MinMaxScaler(), LogisticRegression()),\n",
    "        make_pipeline(StandardScaler(), LogisticRegression(C=30)),\n",
    "        make_pipeline(StandardScaler(), SVC(kernel='rbf')),\n",
    "        make_pipeline(MinMaxScaler(), KNeighborsClassifier()),\n",
    "        RandomForestClassifier(n_estimators=1000, n_jobs=-1),\n",
    "        make_pipeline(MinMaxScaler(), MLPClassifier(hidden_layer_sizes=(150, 100)))\n",
    "    ]\n",
    "\n",
    "    all_scores = list()\n",
    "    for clf in classifiers:\n",
    "        score = evaluate_model(clf, X_train, y_train, X_test, y_test)\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"{clf}\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lG8P2or0n_af"
   },
   "source": [
    "<br>\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Every data set is different, but on this specific data set LSTM and 1D_CNN_LSTM are the models that best performed, achieving an accuracy significally higher than the rest of the models.\n",
    "\n",
    "I didn't want to focus on the computational time of each model on this comparison, but the Wavelet Time Scattering technique was by far the fastest one, concadenating the WTS with a fast classifier it could take less than 15 seconds to train the model and make a prediction. 1D-CNN is also very fast, the LSTM and 2D-CNN models I had to run most of them on the cloud, while the 1D-CNN models I was able to run them on my laptop on a reasonable amount of time. \n",
    "\n",
    "On the other hand, the classification using the time/frequency representation of the signals (scalograms) did not achieved good results.\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1_Demostration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
